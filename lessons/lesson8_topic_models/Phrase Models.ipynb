{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Models\n",
    "\n",
    "###### Author: Alex Sherman | alsherman@deloitte.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from collections import defaultdict\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from IPython.core.display import display, HTML\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "\n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('../../config.ini')\n",
    "DB_PATH = config['DATABASES']['PROJECT_DB_PATH']\n",
    "AIRLINE_ACRONYMS_FILEPATH = config['NLP']['AIRLINE_ACRONYMS_FILEPATH']\n",
    "GENSIM_DICTIONARY_PATH = config['NLP']['GENSIM_DICTIONARY_PATH']\n",
    "GENSIM_CORPUS_PATH = config['NLP']['GENSIM_CORPUS_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DB_PATH)\n",
    "df = pd.read_sql(\"SELECT * FROM Sections\", con=engine)\n",
    "\n",
    "# filter to relevant sections\n",
    "df = df[df['section_text'].str.contains('fee')][0:50]\n",
    "text = ' '.join([section for section in df['section_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# load spacy nlp model\n",
    "# use 'en' if you don't have the lg model\n",
    "%time\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dict of airline acronyms for text preprocessing\n",
    "\n",
    "SOURCE: https://www.faa.gov/airports/resources/acronyms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_acronyms = pd.read_csv(AIRLINE_ACRONYMS_FILEPATH)\n",
    "\n",
    "acronyms = {}\n",
    "acronyms_to_remove = ['basic','grade','self','cat','tsa','map','did','far']\n",
    "for ind, row in airline_acronyms.iterrows():\n",
    "    acronym = row['Acronym'].lower()\n",
    "    definition = row['Definition'].lower().strip().replace(' ','_')\n",
    "    # ignore two character acronyms as they often match actual words\n",
    "    # e.g. 'at' == 'air traffic'\n",
    "    if (len(acronym) > 2) and (acronym not in acronyms_to_remove):\n",
    "        acronyms[acronym] = definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### collect sentences about fees for phrase model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_phrase_model_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end]\n",
    "\n",
    "    # Keep only words, lemmatize tokens, remove punctuation\n",
    "    sent = [str(token.lemma_).lower() \n",
    "            for token in span.sent if token.is_alpha]\n",
    "    \n",
    "    # replace acronyms\n",
    "    sent = [acronyms[token] if token in acronyms else token for token in sent]\n",
    "\n",
    "    matched_sents.append(sent)\n",
    "\n",
    "matched_sents = []\n",
    "pattern = [[{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'fee'}]\n",
    "         ,[{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'fees'}]]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('fees', collect_phrase_model_sents, *pattern)\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Model\n",
    "\n",
    "Phrase modeling is another approach to learning combinations of tokens that together represent meaningful multi-word concepts. We can develop phrase models by looping over the the words in our reviews and looking for words that co-occur (i.e., appear one after another) together much more frequently than you would expect them to by random chance. The formula our phrase models will use to determine whether two tokens $A$ and $B$ constitute a phrase is:\n",
    "\n",
    "$$\\frac{count(A\\ B) - count_{min}}{count(A) * count(B)} * N > threshold$$\n",
    "\n",
    "- $count(A)$ is the number of times token $A$ appears in the corpus\n",
    "- $count(B)$ is the number of times token $B$ appears in the corpus\n",
    "- $count(A\\ B)$ is the number of times the tokens $A\\ B$ appear in the corpus in order\n",
    "- $N$ is the total size of the corpus vocabulary\n",
    "- $count_{min}$ is a user-defined parameter to ensure that accepted phrases occur a minimum number of times\n",
    "- $threshold$ is a user-defined parameter to control how strong of a relationship between two tokens the model requires before accepting them as a phrase\n",
    "\n",
    "Once our phrase model has been trained on our corpus, we can apply it to new text. When our model encounters two tokens in new text that identifies as a phrase, it will merge the two into a single new token.\n",
    "\n",
    "Phrase modeling is superficially similar to named entity detection in that you would expect named entities to become phrases in the model (so new york would become new_york). But you would also expect multi-word expressions that represent common concepts, but aren't specifically named entities (such as happy hour) to also become phrases in the model.\n",
    "\n",
    "We turn to the indispensible gensim library to help us with phrase modeling — the Phrases class in particular.\n",
    "\n",
    "SOURCE: https://github.com/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_terms = list(STOP_WORDS)\n",
    "phrases = Phrases(matched_sents\n",
    "                  , common_terms=common_terms\n",
    "                  , min_count=5\n",
    "                  , threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrases Params\n",
    "\n",
    "- **scoring:** specifies how potential phrases are scored for comparison to the threshold setting. scoring can be set with either a string that refers to a built-in scoring function, or with a function with the expected parameter names. Two built-in scoring functions are available by setting scoring to a string:\n",
    "\n",
    "    - ‘default’: from “Efficient Estimaton of Word Representations in Vector Space” by Mikolov, et. al.: \n",
    "    \n",
    "$$\\frac{count(AB) - count_{min}}{count(A) * count(B)} * N > threshold$$\n",
    "    \n",
    "    - where N is the total vocabulary size.\n",
    "    - Thus, it is easier to exceed the threshold when the two words occur together often or when the two words are rare (i.e. small product)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **common_terms:** optionnal list of “stop words” that won’t affect frequency count of expressions containing them.\n",
    "    - The common_terms parameter add a way to give special treatment to common terms (aka stop words) such that their presence between two words won’t prevent bigram detection. It allows to detect expressions like “bank of america” or “eye of the beholder”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phrases object still contains all the source text in memory. A gensim Phraser will remove this extra data to become smaller and somewhat faster than using the full Phrases model. To determine what data to remove, the Phraser ues the  results of the source model’s min_count, threshold, and scoring settings. (You can tamper with those & create a new Phraser to try other values.)\n",
    "\n",
    "SOURCE: https://radimrehurek.com/gensim/models/phrases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_phrases(phraser, text_stream, num_underscores=1):\n",
    "    phrases = []\n",
    "    for terms in phraser[text_stream]:\n",
    "        for term in terms:\n",
    "            if term.count('_') >= num_underscores:\n",
    "                phrases.append(term)\n",
    "    print(set(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'require_airline', 'flight_cancel', 'airtran_and_to_delta', 'luggage_iii', 'required_navigation_performance', 'deny_board', 'allege_anticompetitive', 'available_seat_mile', 'optional_service', 'difference_in_airfare', 'ancillary_service', 'sherman_act', 'department_of_transportation', 'permanently_lose', 'damage_for_the_amount_of_first_baggage', 'rental_expense', 'rules_also_require', 'prominently_disclose', 'check_bag', 'complaint_seek', 'injunctive_relief', 'violation_of_section', 'refund_any_check', 'bump_from_flight', 'passenger_protection', 'broad_range', 'consolidated_amended', 'unable_to_take_advantage', 'section_of_the_sherman', '-pron-_website', 'charge_a_change', 'passenger_be_allow', 'approximately_percent', 'addition_to_treble'}\n"
     ]
    }
   ],
   "source": [
    "print_phrases(bigram, matched_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-gram phrase model\n",
    "\n",
    "We can place the text from the first phrase model into another Phrases object to create n-term phrase models. We can repear this process multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refund_any_check_bag', 'flight_cancel_or_oversell', 'allege_anticompetitive_activity', 'injunctive_relief_against_a_broad_range', 'required_navigation_performance', 'passenger_protection_rules_also_require', 'consolidated_amended_complaint_seek', 'permanently_lose_luggage_iii', 'available_seat_mile', 'difference_in_airfare', 'department_of_transportation', 'pay_for_ancillary_service', 'addition_to_treble_damage_for_the_amount_of_first_baggage', 'bump_from_flight_ii', 'passenger_be_unable_to_take_advantage', 'bump_from_flight', 'optional_service_on_-pron-_website', 'pay_to_airtran_and_to_delta', 'section_of_the_sherman', 'violation_of_section_of_the_sherman_act', 'prominently_disclose_all_potential', 'deny_board_compensation', 'charge_a_change', 'passenger_be_allow'}\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(bigram[matched_sents], common_terms=common_terms, min_count=5,threshold=5)\n",
    "trigram = Phraser(phrases)\n",
    "\n",
    "print_phrases(trigram, bigram[matched_sents], num_underscores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC NUMBER: 6\n",
      "\n",
      "ORIGINAL SENTENT: in august the department_of_transportation implement new rule expand the passenger protection rule by among other thing i increase the maximum deny board compensation airline must pay to passenger bump from flight from to ii require airline to refund any check bag fee for permanently lose luggage iii require airline to prominently disclose all potential fee for optional service on -pron- website and iv require airline to refund passenger fee pay for ancillary service if a flight cancel or oversell and a passenger be unable to take advantage of such service\n",
      "\n",
      "BIGRAM: in august the department_of_transportation implement new rule expand the passenger_protection rule by among other thing i increase the maximum deny_board compensation airline must pay to passenger bump_from_flight from to ii require_airline to refund_any_check bag fee for permanently_lose luggage_iii require_airline to prominently_disclose all potential fee for optional_service on -pron-_website and iv require_airline to refund passenger fee pay for ancillary_service if a flight_cancel or oversell and a passenger be unable_to_take_advantage of such service\n",
      "\n",
      "TRIGRAM: in august the department_of_transportation implement new rule expand the passenger_protection rule by among other thing i increase the maximum deny_board_compensation airline must pay to passenger bump_from_flight from to ii require_airline to refund_any_check_bag fee for permanently_lose_luggage_iii require_airline to prominently_disclose_all_potential fee for optional_service_on_-pron-_website and iv require_airline to refund_passenger fee pay_for_ancillary_service if a flight_cancel_or_oversell and a passenger_be_unable_to_take_advantage of such service\n"
     ]
    }
   ],
   "source": [
    "for doc_num in [6]:\n",
    "    print('DOC NUMBER: {}\\n'.format(doc_num))\n",
    "    print('ORIGINAL SENTENT: {}\\n'.format(' '.join(matched_sents[doc_num])))\n",
    "    print('BIGRAM: {}\\n'.format(' '.join(bigram[matched_sents[doc_num]])))\n",
    "    print('TRIGRAM: {}'.format(' '.join(trigram[bigram[matched_sents[doc_num]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Phrase Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Terminal_1_Modernization_Project', 'A-List_Preferred”_Rapid_Rewards_Members_booking_on', 'The_U.S._Department_of_Transportation', 'Initiatives_-_Business_Traveler_Amenities', 'The_Passenger_Protection_Rules', 'the_FAA_Modernization_and_Reform_Act', 'New_York_LaGuardia_Airport', 'Wanna_Get_Away', 'Facilities_Maintenance_Technicians', 'the_Wartime_Act', 'the_Company,_the_Company', 'the_Passenger_Protection_Rule', 'the_U.S._Congress', 'Amadeus_IT_Group', 'Hollywood_International_Airport', 'the_Northern_District', 'AirTran_A+_Rewards', 'Consolidated_Amended_Complaint', 'the_Customer_Service_Agents', '2013_the_Company', 'the_Department_of_Homeland_Security', 'Washington_Reagan_National_Airport', 'the_FAA_Modernization_and_Reform__Act', 'the_United_States_District_Court', 'Occupational_Safety_and_Health_Administration_and_Food_and_Drug_Administration', 'Hartsfield-_Jackson_Atlanta_International_Airport', '“Business_Select', 'A+_Miles_Rewards', 'the_Consolidated_Amended_Complaint', 'the_Aircraft_Mechanics', 'the_Terminal_1_Modernization_Project', 'A-List_and_100%', 'A-List_Preferred”', 'MAX_8_aircraft', 'Air_Carrier_Operating_Certificate', 'MAX_7_aircraft', 'Consolidated_Balance_Sheet', 'the_Facilities_Agreement', 'the_Aviation_and_Transportation_Security_Act', 'EarlyBird_Check-in', 'the_Transportation_Security_Administration', 'the_United_States', 'Aggressive_Promotion_of_the_Company’s_Points_of_Differentiation', 'the_Company’s_Board_of_Directors', 'B717_to_Delta', 'the_Passenger_Protection_Rules', 'A-List_Customers', 'the_Love_Field_Airport_Modernization_Corporation', 'Customer_Support_and_Services', 'the_Company’s_Maintenance', 'Operating_Strategies_and_Initiatives_-_Ancillary_Services', 'the_Company’s_Depreciation', 'Wartime_Supplemental_Appropriations_Act', 'The_Atlanta_Customer_Support_and_Services', 'Delta_Air_Lines,_Inc.', 'a_Memorandum_of_Agreement', 'the_Company_for_the_Facilities_Payments', 'the_“TSA”', 'A-List_Preferred', 'the_Company’s_Operating', 'the_Revenue_Credit_Agreement', 'the__Company’s', 'Rapid_Rewards_Members', 'the_Consolidated_Financial_Statements', '“Passenger_Protection_Rule', 'the_Consolidated_Financial_Statements_Includes', 'the_Department_of_Justice', 'the_City_of_Dallas', 'AirTran,_Depreciation', 'the_Consolidated_Statement_of_Income', 'the_“9/11_Fee”', 'the_Aircraft_Mechanics_Fraternal_Association', 'Pets_Are_Welcome_on', '“Business_Select”', 'Dallas_Love_Field', 'EarlyBird_Check-In', 'William_P._Hobby_Airport', '“ASR_Programs', 'GE_Engine_Services', 'the_LFMP_Bonds', 'Section_1_of_the_Sherman_Act', 'Orlando_International_Airport', 'Rapid_Rewards_Partners', 'Aviation_Security_Infrastructure_Fee', 'New_Reservation_System', 'Boeing_Capital_Corp.', 'Program_Development_Agreement', 'AirTran_Business_Class', 'the_Aviation_Security_Infrastructure_Fee', 'their_Seniority_Integration_Agreement', 'the_“Wartime_Act”', 'U.S._Customs_and_Border_Protection', 'the_Dallas_City_Council', 'Jackson-Evers_International_Airport', 'Southwest_of_Customer_Service', 'the_LFMP_Bonds_(Facilities_Payments', 'Section_2_of_the_Sherman_Act', 'Management’s_Discussion_and_Analysis_of_Financial_Condition_and_Results_of_Operations', '“Bags_Fly_Free', 'The_Passenger_Protection_Rule', 'Stipulation_and_Order', 'the_Transportation_Security_Fee', 'Phoenix_Sky_Harbor', 'the_Internal_Revenue_Service', 'Certificate_of_Public_Convenience_&_Necessity', 'the_Company_for', 'Company’s_Aircraft', 'Air_Carrier_Certificate', '“Inflight_WiFi_and_Entertainment”', 'the_International_Brotherhood_of_Teamsters', 'the_Company’s_Acquisition', 'a_“Facilities_Agreement”', 'Consolidated_Statement_of_Cash_Flows', '“Management’s_Discussion_and_Analysis_of_Financial_Condition_and_Results_of_Operations”', 'Key_West_International_Airport', 'Ramp,_Operations,_Provisioning', '”_“AnytimeSM,', 'the_Facilities_Payments', 'Certificate_of_Public_Convenience', 'the_City_of_Houston', 'AirTran_717-200', 'The_Company’s', 'US_Airways_Group,_Inc.', 'the_Love_Field_Modernization_Program', '“Operating_Strategies_and_Initiatives', '“Facilities_Agreement”', 'Cabo_San_Lucas', 'the_International_Association_of_Machinists_and_Aerospace_Workers,_AFL-CIO', 'the_“Facilities_Payments”', 'the_B717s_to_Delta', 'the_U.S._Department_of_Homeland_Security', '“Passenger_Protection_Rules', 'International_Capabilities_and_New_Reservation_System', 'the_City_of_Dallas’', 'American_Airlines,_Inc.', 'Revenue_Credit_Agreement'}\n"
     ]
    }
   ],
   "source": [
    "def clean_text(doc):\n",
    "    ents = nlp(doc.text).ents\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    IGNORE_ENTS = ('QUANTITY','ORDINAL','CARDINAL','DATE'\n",
    "                   ,'PERCENT','MONEY','TIME')\n",
    "    ents = [ent for ent in ents if \n",
    "             (ent.label_ not in IGNORE_ENTS) and (len(ent) > 2)]\n",
    "    \n",
    "    # add underscores to combine words in entities\n",
    "    ents = [str(ent).strip().replace(' ','_') for ent in ents]\n",
    "    \n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc if \n",
    "           token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    doc.extend([entity for entity in ents])\n",
    "    \n",
    "    return [str(term) for term in doc]\n",
    "\n",
    "    \n",
    "# combined terms before phrase_model (entities and/or noun chunks)\n",
    "before_phrase = []\n",
    "for sent in doc.sents:\n",
    "    text = clean_text(sent)\n",
    "    for term in text:\n",
    "        if '_' in term:\n",
    "            before_phrase.append(term)\n",
    "\n",
    "print(set(before_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Terminal_1_Modernization_Project', 'A-List_Preferred”_Rapid_Rewards_Members_booking_on', 'The_U.S._Department_of_Transportation', 'Initiatives_-_Business_Traveler_Amenities', 'The_Passenger_Protection_Rules', 'the_FAA_Modernization_and_Reform_Act', 'New_York_LaGuardia_Airport', 'Wanna_Get_Away', 'pay_for_ancillary_service', 'Facilities_Maintenance_Technicians', 'the_Wartime_Act', 'the_Company,_the_Company', 'addition_to_treble_damage_for_the_amount_of_first_baggage', 'the_U.S._Congress', 'passenger_be_unable_to_take_advantage', 'Amadeus_IT_Group', 'Hollywood_International_Airport', 'the_Northern_District', 'bump_from_flight', 'AirTran_A+_Rewards', 'Consolidated_Amended_Complaint', 'the_Customer_Service_Agents', '2013_the_Company', 'the_Department_of_Homeland_Security', 'Washington_Reagan_National_Airport', 'the_FAA_Modernization_and_Reform__Act', 'the_United_States_District_Court', 'Occupational_Safety_and_Health_Administration_and_Food_and_Drug_Administration', 'Hartsfield-_Jackson_Atlanta_International_Airport', 'section_of_the_sherman', '“Business_Select', 'A+_Miles_Rewards', 'the_Consolidated_Amended_Complaint', 'the_Aircraft_Mechanics', 'the_Terminal_1_Modernization_Project', 'A-List_and_100%', 'A-List_Preferred”', 'MAX_8_aircraft', 'Air_Carrier_Operating_Certificate', 'MAX_7_aircraft', 'require_airline', 'Consolidated_Balance_Sheet', 'flight_cancel_or_oversell', 'the_Facilities_Agreement', 'the_Aviation_and_Transportation_Security_Act', 'EarlyBird_Check-in', 'the_Transportation_Security_Administration', 'passenger_protection_rules_also_require', 'consolidated_amended_complaint_seek', 'permanently_lose_luggage_iii', 'the_United_States', 'Aggressive_Promotion_of_the_Company’s_Points_of_Differentiation', 'the_Company’s_Board_of_Directors', 'difference_in_airfare', 'refund_passenger', 'Revenue_Credit_Agreement', 'B717_to_Delta', 'the_Passenger_Protection_Rules', 'A-List_Customers', 'the_Love_Field_Airport_Modernization_Corporation', 'bump_from_flight_ii', 'Customer_Support_and_Services', 'the_Company’s_Maintenance', 'Operating_Strategies_and_Initiatives_-_Ancillary_Services', 'the_Company’s_Depreciation', 'Wartime_Supplemental_Appropriations_Act', 'The_Atlanta_Customer_Support_and_Services', 'passenger_protection', 'Delta_Air_Lines,_Inc.', 'treble_damage', 'a_Memorandum_of_Agreement', 'consolidated_amended', 'the_Company_for_the_Facilities_Payments', 'website_and_iv', 'the_“TSA”', 'prominently_disclose_all_potential', 'charge_a_change', 'A-List_Preferred', 'the_Company’s_Operating', 'the_Revenue_Credit_Agreement', 'approximately_percent', 'the__Company’s', 'Rapid_Rewards_Members', 'the_Consolidated_Financial_Statements', '“Passenger_Protection_Rule', 'refund_any_check_bag', 'allege_anticompetitive_activity', 'the_Consolidated_Financial_Statements_Includes', 'the_Department_of_Justice', 'the_City_of_Dallas', 'injunctive_relief_against_a_broad_range', 'AirTran,_Depreciation', 'the_Consolidated_Statement_of_Income', 'the_“9/11_Fee”', 'the_Aircraft_Mechanics_Fraternal_Association', 'Pets_Are_Welcome_on', '“Business_Select”', 'ancillary_service', 'Dallas_Love_Field', 'EarlyBird_Check-In', 'William_P._Hobby_Airport', '“ASR_Programs', 'GE_Engine_Services', 'the_LFMP_Bonds', 'Section_1_of_the_Sherman_Act', 'Orlando_International_Airport', 'Rapid_Rewards_Partners', 'Aviation_Security_Infrastructure_Fee', 'complaint_seek', 'injunctive_relief', 'Program_Development_Agreement', 'New_Reservation_System', 'Boeing_Capital_Corp.', 'AirTran_Business_Class', 'the_Aviation_Security_Infrastructure_Fee', 'their_Seniority_Integration_Agreement', 'the_“Wartime_Act”', 'U.S._Customs_and_Border_Protection', 'the_Dallas_City_Council', 'Jackson-Evers_International_Airport', 'pay_to_airtran_and_to_delta', 'Southwest_of_Customer_Service', 'deny_board_compensation', 'the_LFMP_Bonds_(Facilities_Payments', 'Section_2_of_the_Sherman_Act', 'Management’s_Discussion_and_Analysis_of_Financial_Condition_and_Results_of_Operations', '“Bags_Fly_Free', 'The_Passenger_Protection_Rule', 'Stipulation_and_Order', 'the_Transportation_Security_Fee', 'Phoenix_Sky_Harbor', 'the_Internal_Revenue_Service', 'Certificate_of_Public_Convenience_&_Necessity', 'the_Company_for', 'Company’s_Aircraft', 'Air_Carrier_Certificate', '“Inflight_WiFi_and_Entertainment”', 'the_International_Brotherhood_of_Teamsters', 'the_Company’s_Acquisition', 'bag_fee', 'optional_service', 'a_“Facilities_Agreement”', 'Consolidated_Statement_of_Cash_Flows', '“Management’s_Discussion_and_Analysis_of_Financial_Condition_and_Results_of_Operations”', 'rental_expense', 'Key_West_International_Airport', 'Ramp,_Operations,_Provisioning', '”_“AnytimeSM,', 'check_bag', 'the_Facilities_Payments', 'Certificate_of_Public_Convenience', 'the_City_of_Houston', 'AirTran_717-200', 'The_Company’s', 'US_Airways_Group,_Inc.', 'the_Love_Field_Modernization_Program', '“Operating_Strategies_and_Initiatives', '“Facilities_Agreement”', 'Cabo_San_Lucas', 'the_International_Association_of_Machinists_and_Aerospace_Workers,_AFL-CIO', 'the_“Facilities_Payments”', 'the_B717s_to_Delta', 'the_U.S._Department_of_Homeland_Security', '“Passenger_Protection_Rules', 'violation_of_section_of_the_sherman_act', 'International_Capabilities_and_New_Reservation_System', 'the_City_of_Dallas’', 'passenger_be_allow', 'American_Airlines,_Inc.', 'the_Passenger_Protection_Rule'}\n"
     ]
    }
   ],
   "source": [
    "def clean_text(doc):\n",
    "    ents = nlp(doc.text).ents\n",
    "\n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    IGNORE_ENTS = ('QUANTITY','ORDINAL','CARDINAL','DATE'\n",
    "                   ,'PERCENT','MONEY','TIME')\n",
    "    ents = [ent for ent in ents if \n",
    "             (ent.label_ not in IGNORE_ENTS) and (len(ent) > 2)]\n",
    "    \n",
    "    # add underscores to combine words in entities\n",
    "    ents = [str(ent).strip().replace(' ','_') for ent in ents]\n",
    "    \n",
    "    # clean text for phrase model\n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc_ = [token.lemma_ for token in doc if token.is_alpha]\n",
    "    phrase_text = [str(term) for term in doc_]\n",
    "    sent = trigram[bigram[phrase_text]]\n",
    "    phrases = []\n",
    "    for term in sent:\n",
    "        if '_' in term:\n",
    "            phrases.append(term)\n",
    "\n",
    "    # remove stops words - \n",
    "    # separate step as they are needed for the phrase model\n",
    "    doc = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    # add phrases and entities\n",
    "    doc.extend([entity for entity in ents])\n",
    "    clean_text = [str(term) for term in doc] + phrases\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# combined terms after phrase model\n",
    "after_phrase = []\n",
    "for sent in doc.sents:\n",
    "    text = clean_text(sent)\n",
    "    for term in text:\n",
    "        if '_' in term:\n",
    "            after_phrase.append(term)\n",
    "\n",
    "print(set(after_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no', 'show', 'policy', 'fund', 'apply', 'future', 'travel', 'southwest', 'change', 'fee', 'future_travel'], ['for', 'example', 'company', 'transfarencysm', 'campaign', 'emphasize', 'southwest', 'approach', 'treat', 'customer', 'fairly', 'honestly', 'respectfully', 'low', 'fare', 'unexpected', 'bag', 'fee', 'change', 'fee', 'hidden', 'fee', 'low_fare', 'bag_fee']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = []\n",
    "for sent in matched_sents:\n",
    "    text = clean_text(sent)\n",
    "    cleaned_text.append(text)\n",
    "\n",
    "print(cleaned_text[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline.index      airline.mm         airline.mm.index   airline_dict.dict\r\n"
     ]
    }
   ],
   "source": [
    "ls ../raw_data/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the cleaned text to a new file for later use\n",
    "with open(AIRLINE_CLEANED_TEXT_PATH, 'w') as f:\n",
    "    for line in cleaned_text:\n",
    "        line = ' '.join(line) + '\\n'\n",
    "        f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:guild]",
   "language": "python",
   "name": "conda-env-guild-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
