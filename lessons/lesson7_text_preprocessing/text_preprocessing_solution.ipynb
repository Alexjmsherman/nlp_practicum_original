{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "##### Author: Alex Sherman | alsherman@deloitte.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agenga\n",
    "\n",
    "1. SpaCy\n",
    "2. Text Tagging\n",
    "3. Text Identification\n",
    "4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "\n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('../../config.ini')\n",
    "DB_PATH = config['DATABASES']['PROJECT_DB_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite:///C:\\\\Users\\\\alsherman\\\\Desktop\\\\PycharmProjects\\\\firm_initiatives\\\\ml_guild\\\\raw_data\\\\databases\\\\annual_report.db'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm DB_PATH is correct db directory, otherwise the rest of the code will not work\n",
    "DB_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOCUMENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECTIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name\n",
       "0  DOCUMENTS\n",
       "1   SECTIONS"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the names of the tables in the database\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(DB_PATH)\n",
    "pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table'\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>document_text</th>\n",
       "      <th>table_text</th>\n",
       "      <th>author</th>\n",
       "      <th>last_modified_by</th>\n",
       "      <th>created</th>\n",
       "      <th>revision</th>\n",
       "      <th>num_tables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...</td>\n",
       "      <td>southwest-airlines-co_annual_report_2012.docx</td>\n",
       "      <td>2012</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2012 ANNUAL REPORT TO S...</td>\n",
       "      <td>2013 . . . . . . . . . . . . . . . . . . . . ....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018-01-03 22:49:42</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...</td>\n",
       "      <td>southwest-airlines-co_annual_report_2013.docx</td>\n",
       "      <td>2013</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2013 ANNUAL REPORT TO S...</td>\n",
       "      <td>Period  Dividend  High  Low 2013       1st Qua...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018-01-03 22:50:40</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...</td>\n",
       "      <td>southwest-airlines-co_annual_report_2014.docx</td>\n",
       "      <td>2014</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2014 ANNUAL REPORT TO S...</td>\n",
       "      <td>PART I  Item 1. Business  1 Item 1A. Risk Fa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018-01-03 22:51:35</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...</td>\n",
       "      <td>southwest-airlines-co_annual_report_2015.docx</td>\n",
       "      <td>2015</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2015 ANNUAL REPORT TO S...</td>\n",
       "      <td>PART I  Item 1. Business  1 Item 1A. Risk Fa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018-01-03 22:52:25</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...</td>\n",
       "      <td>southwest-airlines-co_annual_report_2016.docx</td>\n",
       "      <td>2016</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2016 ANNUAL REPORT TO S...</td>\n",
       "      <td>PART I  Item 1. Business  1 Item 1A. Risk Fa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018-01-03 22:53:10</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id                                               path  \\\n",
       "0            1  C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...   \n",
       "1            2  C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...   \n",
       "2            3  C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...   \n",
       "3            4  C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...   \n",
       "4            5  C:\\Users\\alsherman\\Desktop\\PycharmProjects\\fir...   \n",
       "\n",
       "                                        filename  year  \\\n",
       "0  southwest-airlines-co_annual_report_2012.docx  2012   \n",
       "1  southwest-airlines-co_annual_report_2013.docx  2013   \n",
       "2  southwest-airlines-co_annual_report_2014.docx  2014   \n",
       "3  southwest-airlines-co_annual_report_2015.docx  2015   \n",
       "4  southwest-airlines-co_annual_report_2016.docx  2016   \n",
       "\n",
       "                                       document_text  \\\n",
       "0  SOUTHWEST AIRLINES CO. 2012 ANNUAL REPORT TO S...   \n",
       "1  SOUTHWEST AIRLINES CO. 2013 ANNUAL REPORT TO S...   \n",
       "2  SOUTHWEST AIRLINES CO. 2014 ANNUAL REPORT TO S...   \n",
       "3  SOUTHWEST AIRLINES CO. 2015 ANNUAL REPORT TO S...   \n",
       "4  SOUTHWEST AIRLINES CO. 2016 ANNUAL REPORT TO S...   \n",
       "\n",
       "                                          table_text author last_modified_by  \\\n",
       "0  2013 . . . . . . . . . . . . . . . . . . . . ....                           \n",
       "1  Period  Dividend  High  Low 2013       1st Qua...                           \n",
       "2    PART I  Item 1. Business  1 Item 1A. Risk Fa...                           \n",
       "3    PART I  Item 1. Business  1 Item 1A. Risk Fa...                           \n",
       "4    PART I  Item 1. Business  1 Item 1A. Risk Fa...                           \n",
       "\n",
       "               created  revision  num_tables  \n",
       "0  2018-01-03 22:49:42         0          48  \n",
       "1  2018-01-03 22:50:40         0          45  \n",
       "2  2018-01-03 22:51:35         0          58  \n",
       "3  2018-01-03 22:52:25         0          53  \n",
       "4  2018-01-03 22:53:10         0          58  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the oracle 10k documents \n",
    "doc_df = pd.read_sql(\"SELECT * FROM Documents\", con=engine)\n",
    "doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>section_name</th>\n",
       "      <th>criteria</th>\n",
       "      <th>section_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>southwest-airlines-co_annual_report_2012.docx</td>\n",
       "      <td>SOUTHWEST AIRLINES CO. 2012 ANNUAL REPORT TO ...</td>\n",
       "      <td>&lt;function style at 0x00000227334AA048&gt;</td>\n",
       "      <td>To our Shareholders: The year 2012 represented...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>southwest-airlines-co_annual_report_2012.docx</td>\n",
       "      <td>AIRTRAN INTEGRATION: WE ARE ON TRACK WITH OUR ...</td>\n",
       "      <td>&lt;function capitalization at 0x000002273349EF28&gt;</td>\n",
       "      <td>In December 2012, we announced new 2013 revenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>southwest-airlines-co_annual_report_2012.docx</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>&lt;function style at 0x00000227334AA048&gt;</td>\n",
       "      <td>Í ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   section_id                                       filename  \\\n",
       "0           1  southwest-airlines-co_annual_report_2012.docx   \n",
       "1           2  southwest-airlines-co_annual_report_2012.docx   \n",
       "2           3  southwest-airlines-co_annual_report_2012.docx   \n",
       "\n",
       "                                        section_name  \\\n",
       "0   SOUTHWEST AIRLINES CO. 2012 ANNUAL REPORT TO ...   \n",
       "1  AIRTRAN INTEGRATION: WE ARE ON TRACK WITH OUR ...   \n",
       "2  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "\n",
       "                                          criteria  \\\n",
       "0           <function style at 0x00000227334AA048>   \n",
       "1  <function capitalization at 0x000002273349EF28>   \n",
       "2           <function style at 0x00000227334AA048>   \n",
       "\n",
       "                                        section_text  \n",
       "0  To our Shareholders: The year 2012 represented...  \n",
       "1  In December 2012, we announced new 2013 revenu...  \n",
       "2  Í ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the oracle 10k sections\n",
    "df = pd.read_sql(\"SELECT * FROM Sections \", con=engine)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15                                                AIRTRAN\n",
       "20      SOUTHWEST’S ALL-NEW RAPID REWARDS FREQUENT FLY...\n",
       "26      AGGRESSIVE PROMOTION OF THE COMPANY’S POINTS O...\n",
       "28                            ANCILLARY SERVICES AND FEES\n",
       "34      ECONOMIC AND OPERATIONAL REGULATION THE U.S. D...\n",
       "35                                         AVIATION TAXES\n",
       "38                                    SECURITY REGULATION\n",
       "43                             PRICING AND COST STRUCTURE\n",
       "54      THE COMPANY’S LOW-COST STRUCTURE HAS HISTORICA...\n",
       "73      AIRTRAN IS CURRENTLY SUBJECT TO PENDING ANTITR...\n",
       "79                         GROUND FACILITIES AND SERVICES\n",
       "80                              ITEM 3. LEGAL PROCEEDINGS\n",
       "92                                         YEAR IN REVIEW\n",
       "94                                     OPERATING REVENUES\n",
       "98      AVERAGE BRENT CRUDE OIL ESTIMATED DIFFERENCE I...\n",
       "104                                         CHANGE CHANGE\n",
       "107                   OBLIGATIONS BY PERIOD (IN MILLIONS)\n",
       "109                                   REVENUE RECOGNITION\n",
       "144           EXPENSES RELATED TO THE AIRTRAN ACQUISITION\n",
       "151     OTHER ASSETS AND LIABILITIES, AND OTHER OPERAT...\n",
       "155                                                LEASES\n",
       "254                                               AIRTRAN\n",
       "264     AGGRESSIVE PROMOTION OF THE COMPANY’S POINTS O...\n",
       "266                           ANCILLARY SERVICES AND FEES\n",
       "272     ECONOMIC AND OPERATIONAL REGULATION CONSUMER P...\n",
       "273                                        AVIATION TAXES\n",
       "275            OPERATIONAL, SAFETY, AND HEALTH REGULATION\n",
       "281                            PRICING AND COST STRUCTURE\n",
       "292     THE COMPANY’S LOW-COST STRUCTURE HAS HISTORICA...\n",
       "309     AIRTRAN IS CURRENTLY SUBJECT TO PENDING ANTITR...\n",
       "                              ...                        \n",
       "739     ECONOMIC AND OPERATIONAL REGULATION CONSUMER P...\n",
       "740                               AVIATION TAXES AND FEES\n",
       "747                            PRICING AND COST STRUCTURE\n",
       "757     THE COMPANY’S LOW-COST STRUCTURE HAS HISTORICA...\n",
       "765     AIRPORT CAPACITY CONSTRAINTS AND AIR TRAFFIC C...\n",
       "769     THE COMPANY IS CURRENTLY SUBJECT TO PENDING LI...\n",
       "775                        GROUND FACILITIES AND SERVICES\n",
       "776                             ITEM 3. LEGAL PROCEEDINGS\n",
       "793            2015 COMPARED WITH 2014 OPERATING REVENUES\n",
       "797     AVERAGE BRENT CRUDE OIL ESTIMATED ECONOMIC JET...\n",
       "801            2014 COMPARED WITH 2013 OPERATING REVENUES\n",
       "802               YEAR ENDED DECEMBER 31, PER ASM PERCENT\n",
       "812                                   REVENUE RECOGNITION\n",
       "850                              OTHER OPERATING EXPENSES\n",
       "853                                                LEASES\n",
       "942                                FARE STRUCTURE GENERAL\n",
       "946                                             MARKETING\n",
       "949     ECONOMIC AND OPERATIONAL REGULATION CONSUMER P...\n",
       "950                               AVIATION TAXES AND FEES\n",
       "957                            PRICING AND COST STRUCTURE\n",
       "967     THE COMPANY’S LOW-COST STRUCTURE HAS HISTORICA...\n",
       "974     AIRPORT CAPACITY CONSTRAINTS AND AIR TRAFFIC C...\n",
       "983                        GROUND FACILITIES AND SERVICES\n",
       "984                      ITEM 3.        LEGAL PROCEEDINGS\n",
       "1000    AVERAGE BRENT CRUDE OIL ESTIMATED ECONOMIC JET...\n",
       "1002           2015 COMPARED WITH 2014 OPERATING REVENUES\n",
       "1003              YEAR ENDED DECEMBER 31, PER ASM PERCENT\n",
       "1016                                  REVENUE RECOGNITION\n",
       "1052                             OTHER OPERATING EXPENSES\n",
       "1055                                               LEASES\n",
       "Name: section_name, Length: 94, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.section_text.str.contains('fee')].section_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During 2016, the Company continued to aggressively market and benefit from Southwest’s points of differentiation from its competitors. For example, the Company’s TransfarencySM  campaign emphasizes Southwest’s approach to treating Customers fairly, honestly, and respectfully, with its low fares and no unexpected bag fees, change fees, or hidden fees. Southwest continues to be the only major U.S. airline that offers to all ticketed Customers up to two checked bags that fly free (weight and size limits apply). Through both its national and local marketing campaigns, Southwest has continued to aggressively promote this point of differentiation from its competitors with its “Bags Fly Free®” message. The Company believes its decision not to charge for first and second checked bags, as reinforced by the Company’s related marketing, has driven an increase in the Company’s market share and a resulting net increase in revenues. Southwest is also the only major U.S. airline that does not charge a fee on any of its fares for a Customer change in flight reservations. The Company has continued to incorporate this key point of differentiation in its marketing campaigns. The campaigns highlight the importance to Southwest of Customer Service by showing that Southwest understands plans can change and therefore does not charge a change fee. While a Customer may pay a difference in airfare, the Customer will not be charged a change fee on top of any difference in airfare. Also unlike most of its competitors, Southwest does not impose additional fees for items such as seat selection, snacks, curb-side check-in, and telephone reservations. In addition, Southwest allows each ticketed Customer to check one stroller and one car seat free of charge, in addition to the two free checked bags. The Company also continues to promote all of the many other reasons to fly Southwest such as its low fares, network size, Customer Service, free live television offerings, and its Rapid Rewards frequent flyer program. In 2014, the Company launched a new visual expression of its brand - Heart - to symbolize the Company’s care, trust, and belief in providing exceptional Hospitality, and its Employees’ dedication  to connecting Customers with what is important in their lives. The Company introduced a new Heart aircraft livery, airport experience, and logo. Aircraft already in the Company’s fleet were scheduled to receive the newly painted livery within the aircraft’s existing repainting schedule, while new aircraft have been delivered in the Heart livery. In 2016, the Company unveiled the next phase of the Heart brand with the introduction of its first aircraft with a new Heart cabin interior. The new 737-800 interiors, which will also be included in the Company’s 737-8 aircraft, give Southwest Customers a look and feel of the future, with bold blue seats and additional seat width and legroom, an adjustable headrest, enhanced back comfort, and extra room for personal belongings. In addition, in mid-2017, front-line Employees will begin wearing Employee-designed uniforms that highlight the Company’s red and blue Heart brand.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example text\n",
    "text = df.section_text[946]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy\n",
    "\n",
    "#### Installation:\n",
    "- Download Microsoft Visual C++: http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "- conda install -c conda-forge spacy\n",
    "- python -m spacy download en\n",
    "\n",
    "##### if you run into an error try the following:\n",
    "- python -m spacy link en_core_web_sm en\n",
    "- SOURCE: https://github.com/explosion/spaCy/issues/950\n",
    "\n",
    "##### Optional to install a convolutional neural network model:\n",
    "- python -m spacy download en_core_web_lg\n",
    "\n",
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
    "\n",
    "If you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other?\n",
    "\n",
    "spaCy is designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n",
    "\n",
    "spaCy is not research software. It's built on the latest research, but it's designed to get things done. This leads to fairly different design decisions than NLTK or CoreNLP, which were created as platforms for teaching and research. The main difference is that spaCy is integrated and opinionated. spaCy tries to avoid asking the user to choose between multiple algorithms that deliver equivalent functionality. Keeping the menu small lets spaCy deliver generally better performance and developer experience.\n",
    "\n",
    "### SpaCy Features \n",
    "\n",
    "NAME |\tDESCRIPTION |\n",
    ":----- |:------|\n",
    "Tokenization|Segmenting text into words, punctuations marks etc.|\n",
    "Part-of-speech (POS) Tagging|Assigning word types to tokens, like verb or noun.|\n",
    "Dependency Parsing|\tAssigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.|\n",
    "Lemmatization|\tAssigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".|\n",
    "Sentence Boundary Detection (SBD)|\tFinding and segmenting individual sentences.|\n",
    "Named Entity Recognition (NER)|\tLabelling named \"real-world\" objects, like persons, companies or locations.|\n",
    "Similarity|\tComparing words, text spans and documents and how similar they are to each other.|\n",
    "Text Classification|\tAssigning categories or labels to a whole document, or parts of a document.|\n",
    "Rule-based Matching|\tFinding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.|\n",
    "Training|\tUpdating and improving a statistical model's predictions.|\n",
    "Serialization|\tSaving objects to files or byte strings.|\n",
    "\n",
    "SOURCE: https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a English language model\n",
    "#nlp = spacy.load('en')  # simple model\n",
    "nlp = spacy.load('en_core_web_lg')  # cnn model\n",
    "\n",
    "# another approach:\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the document text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "During 2016, the Company continued to aggressively market and benefit from Southwest’s points of differentiation from its competitors. For example, the Company’s TransfarencySM  campaign emphasizes Southwest’s approach to treating Customers fairly, honestly, and respectfully, with its low fares and no unexpected bag fees, change fees, or hidden fees. Southwest continues to be the only major U.S. airline that offers to all ticketed Customers up to two checked bags that fly free (weight and size limits apply). Through both its national and local marketing campaigns, Southwest has continued to aggressively promote this point of differentiation from its competitors with its “Bags Fly Free®” message. The Company believes its decision not to charge for first and second checked bags, as reinforced by the Company’s related marketing, has driven an increase in the Company’s market share and a resulting net increase in revenues. Southwest is also the only major U.S. airline that does not charge a fee on any of its fares for a Customer change in flight reservations. The Company has continued to incorporate this key point of differentiation in its marketing campaigns. The campaigns highlight the importance to Southwest of Customer Service by showing that Southwest understands plans can change and therefore does not charge a change fee. While a Customer may pay a difference in airfare, the Customer will not be charged a change fee on top of any difference in airfare. Also unlike most of its competitors, Southwest does not impose additional fees for items such as seat selection, snacks, curb-side check-in, and telephone reservations. In addition, Southwest allows each ticketed Customer to check one stroller and one car seat free of charge, in addition to the two free checked bags. The Company also continues to promote all of the many other reasons to fly Southwest such as its low fares, network size, Customer Service, free live television offerings, and its Rapid Rewards frequent flyer program. In 2014, the Company launched a new visual expression of its brand - Heart - to symbolize the Company’s care, trust, and belief in providing exceptional Hospitality, and its Employees’ dedication  to connecting Customers with what is important in their lives. The Company introduced a new Heart aircraft livery, airport experience, and logo. Aircraft already in the Company’s fleet were scheduled to receive the newly painted livery within the aircraft’s existing repainting schedule, while new aircraft have been delivered in the Heart livery. In 2016, the Company unveiled the next phase of the Heart brand with the introduction of its first aircraft with a new Heart cabin interior. The new 737-800 interiors, which will also be included in the Company’s 737-8 aircraft, give Southwest Customers a look and feel of the future, with bold blue seats and additional seat width and legroom, an adjustable headrest, enhanced back comfort, and extra room for personal belongings. In addition, in mid-2017, front-line Employees will begin wearing Employee-designed uniforms that highlight the Company’s red and blue Heart brand."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the text\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=https://spacy.io/assets/img/pipeline.svg width=1000 height=200></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_url = 'https://spacy.io/assets/img/pipeline.svg'\n",
    "iframe = '<iframe src={} width=1000 height=200></iframe>'.format(spacy_url)\n",
    "HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off – whereas \"U.K.\" should remain one token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=https://spacy.io/assets/img/tokenization.svg width=650 height=400></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization_url = 'https://spacy.io/assets/img/tokenization.svg'\n",
    "iframe = '<iframe src={} width=650 height=400></iframe>'.format(tokenization_url)\n",
    "HTML(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech (POS) Tagging\n",
    "\n",
    "After tokenization, spaCy can parse and tag a given Doc. This is where the statistical model comes in, which enables spaCy to make a prediction of which tag or label most likely applies in this context. A model consists of binary data and is produced by showing a system enough examples for it to make predictions that generalise across the language – for example, a word following \"the\" in English is most likely a noun.\n",
    "\n",
    "Annotation | Description\n",
    ":----- |:------|\n",
    "Text |The original word text|\n",
    "Lemma |The base form of the word.|\n",
    "POS |The simple part-of-speech tag.|\n",
    "Tag |The detailed part-of-speech tag.|\n",
    "Dep |Syntactic dependency, i.e. the relation between tokens.|\n",
    "Shape |The word shape – capitalisation, punctuation, digits.|\n",
    "Is Alpha |Is the token an alpha character?|\n",
    "Is Stop |Is the token part of a stop list, i.e. the most common words of the language?|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text            | lemma_          | pos_     | tag_     | dep_        | shape_   | is_alpha | is_stop  | \n",
      "________________________________________________________________________________________________________\n",
      "During          | during          | ADP      | IN       | prep        | Xxxxx    |        1 |        0 |\n",
      "2016            | 2016            | NUM      | CD       | pobj        | dddd     |        0 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "continued       | continue        | VERB     | VBD      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "aggressively    | aggressively    | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "market          | market          | VERB     | VB       | xcomp       | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "benefit         | benefit         | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "from            | from            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "points          | point           | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "differentiation | differentiation | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "from            | from            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "competitors     | competitor      | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "For             | for             | ADP      | IN       | prep        | Xxx      |        1 |        0 |\n",
      "example         | example         | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "TransfarencySM  | transfarencysm  | NOUN     | NN       | nmod        | XxxxxXX  |        1 |        0 |\n",
      "                |                 | SPACE    |          |             |          |        0 |        0 |\n",
      "campaign        | campaign        | NOUN     | NN       | nsubj       | xxxx     |        1 |        0 |\n",
      "emphasizes      | emphasize       | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "approach        | approach        | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "to              | to              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "treating        | treat           | VERB     | VBG      | pcomp       | xxxx     |        1 |        0 |\n",
      "Customers       | customer        | NOUN     | NNS      | dobj        | Xxxxx    |        1 |        0 |\n",
      "fairly          | fairly          | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "honestly        | honestly        | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "respectfully    | respectfully    | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "low             | low             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "fares           | fare            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "no              | no              | DET      | DT       | det         | xx       |        1 |        0 |\n",
      "unexpected      | unexpected      | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "bag             | bag             | NOUN     | NN       | compound    | xxx      |        1 |        0 |\n",
      "fees            | fee             | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "change          | change          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "fees            | fee             | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "or              | or              | CCONJ    | CC       | cc          | xx       |        1 |        0 |\n",
      "hidden          | hide            | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "fees            | fee             | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "continues       | continue        | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "be              | be              | VERB     | VB       | xcomp       | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "only            | only            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "major           | major           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "U.S.            | u.s.            | PROPN    | NNP      | compound    | X.X.     |        0 |        0 |\n",
      "airline         | airline         | NOUN     | NN       | attr        | xxxx     |        1 |        0 |\n",
      "that            | that            | ADJ      | WDT      | nsubj       | xxxx     |        1 |        0 |\n",
      "offers          | offer           | VERB     | VBZ      | relcl       | xxxx     |        1 |        0 |\n",
      "to              | to              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "all             | all             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "ticketed        | ticket          | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "Customers       | customer        | NOUN     | NNS      | pobj        | Xxxxx    |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up              | up              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "to              | to              | PART     | TO       | prep        | xx       |        1 |        0 |\n",
      "two             | two             | NUM      | CD       | nummod      | xxx      |        1 |        0 |\n",
      "checked         | check           | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "bags            | bag             | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "that            | that            | ADJ      | WDT      | nsubj       | xxxx     |        1 |        0 |\n",
      "fly             | fly             | VERB     | VBP      | relcl       | xxx      |        1 |        0 |\n",
      "free            | free            | ADJ      | JJ       | advmod      | xxxx     |        1 |        0 |\n",
      "(               | (               | PUNCT    | -LRB-    | punct       | (        |        0 |        0 |\n",
      "weight          | weight          | NOUN     | NN       | nmod        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "size            | size            | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "limits          | limit           | NOUN     | NNS      | nsubj       | xxxx     |        1 |        0 |\n",
      "apply           | apply           | VERB     | VBP      | relcl       | xxxx     |        1 |        0 |\n",
      ")               | )               | PUNCT    | -RRB-    | punct       | )        |        0 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "Through         | through         | ADP      | IN       | prep        | Xxxxx    |        1 |        0 |\n",
      "both            | both            | CCONJ    | CC       | det         | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "national        | national        | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "local           | local           | ADJ      | JJ       | conj        | xxxx     |        1 |        0 |\n",
      "marketing       | marketing       | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "campaigns       | campaign        | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "has             | have            | VERB     | VBZ      | aux         | xxx      |        1 |        0 |\n",
      "continued       | continue        | VERB     | VBN      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "aggressively    | aggressively    | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "promote         | promote         | VERB     | VB       | xcomp       | xxxx     |        1 |        0 |\n",
      "this            | this            | DET      | DT       | det         | xxxx     |        1 |        0 |\n",
      "point           | point           | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "differentiation | differentiation | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "from            | from            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "competitors     | competitor      | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "“               | “               | ADJ      | JJ       | nmod        | “        |        0 |        0 |\n",
      "Bags            | bag             | NOUN     | NNS      | compound    | Xxxx     |        1 |        0 |\n",
      "Fly             | fly             | PROPN    | NNP      | pobj        | Xxx      |        1 |        0 |\n",
      "Free            | free            | ADJ      | JJ       | appos       | Xxxx     |        1 |        0 |\n",
      "®               | ®               | PUNCT    | ''       | punct       | ®        |        0 |        0 |\n",
      "”               | ”               | NOUN     | NN       | compound    | ”        |        0 |        0 |\n",
      "message         | message         | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "believes        | believe         | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "decision        | decision        | NOUN     | NN       | nsubj       | xxxx     |        1 |        0 |\n",
      "not             | not             | ADV      | RB       | neg         | xxx      |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "charge          | charge          | VERB     | VB       | ccomp       | xxxx     |        1 |        0 |\n",
      "for             | for             | ADP      | IN       | prep        | xxx      |        1 |        0 |\n",
      "first           | first           | ADJ      | JJ       | advmod      | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "second          | second          | ADJ      | JJ       | conj        | xxxx     |        1 |        0 |\n",
      "checked         | check           | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "bags            | bag             | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "as              | as              | ADP      | IN       | mark        | xx       |        1 |        0 |\n",
      "reinforced      | reinforce       | VERB     | VBN      | advcl       | xxxx     |        1 |        0 |\n",
      "by              | by              | ADP      | IN       | agent       | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "related         | related         | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "marketing       | marketing       | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "has             | have            | VERB     | VBZ      | aux         | xxx      |        1 |        0 |\n",
      "driven          | drive           | VERB     | VBN      | ccomp       | xxxx     |        1 |        0 |\n",
      "an              | an              | DET      | DT       | det         | xx       |        1 |        0 |\n",
      "increase        | increase        | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "market          | market          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "share           | share           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "resulting       | result          | VERB     | VBG      | amod        | xxxx     |        1 |        0 |\n",
      "net             | net             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "increase        | increase        | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "revenues        | revenue         | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "is              | be              | VERB     | VBZ      | ROOT        | xx       |        1 |        0 |\n",
      "also            | also            | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "only            | only            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "major           | major           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "U.S.            | u.s.            | PROPN    | NNP      | compound    | X.X.     |        0 |        0 |\n",
      "airline         | airline         | NOUN     | NN       | attr        | xxxx     |        1 |        0 |\n",
      "that            | that            | ADJ      | WDT      | nsubj       | xxxx     |        1 |        0 |\n",
      "does            | do              | VERB     | VBZ      | aux         | xxxx     |        1 |        0 |\n",
      "not             | not             | ADV      | RB       | neg         | xxx      |        1 |        0 |\n",
      "charge          | charge          | VERB     | VB       | relcl       | xxxx     |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "fee             | fee             | NOUN     | NN       | dobj        | xxx      |        1 |        0 |\n",
      "on              | on              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "any             | any             | DET      | DT       | pobj        | xxx      |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "fares           | fare            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "for             | for             | ADP      | IN       | prep        | xxx      |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "Customer        | customer        | NOUN     | NN       | compound    | Xxxxx    |        1 |        0 |\n",
      "change          | change          | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "flight          | flight          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "reservations    | reservation     | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "has             | have            | VERB     | VBZ      | aux         | xxx      |        1 |        0 |\n",
      "continued       | continue        | VERB     | VBN      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "incorporate     | incorporate     | VERB     | VB       | xcomp       | xxxx     |        1 |        0 |\n",
      "this            | this            | DET      | DT       | det         | xxxx     |        1 |        0 |\n",
      "key             | key             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "point           | point           | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "differentiation | differentiation | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "marketing       | marketing       | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "campaigns       | campaign        | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "campaigns       | campaign        | NOUN     | NNS      | nsubj       | xxxx     |        1 |        0 |\n",
      "highlight       | highlight       | VERB     | VBP      | ROOT        | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "importance      | importance      | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "to              | to              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | pobj        | Xxxxx    |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "Customer        | customer        | PROPN    | NNP      | compound    | Xxxxx    |        1 |        0 |\n",
      "Service         | service         | PROPN    | NNP      | pobj        | Xxxxx    |        1 |        0 |\n",
      "by              | by              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "showing         | show            | VERB     | VBG      | pcomp       | xxxx     |        1 |        0 |\n",
      "that            | that            | ADP      | IN       | mark        | xxxx     |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "understands     | understand      | VERB     | VBZ      | ccomp       | xxxx     |        1 |        0 |\n",
      "plans           | plan            | NOUN     | NNS      | nsubj       | xxxx     |        1 |        0 |\n",
      "can             | can             | VERB     | MD       | aux         | xxx      |        1 |        0 |\n",
      "change          | change          | VERB     | VB       | ccomp       | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "therefore       | therefore       | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "does            | do              | VERB     | VBZ      | aux         | xxxx     |        1 |        0 |\n",
      "not             | not             | ADV      | RB       | neg         | xxx      |        1 |        0 |\n",
      "charge          | charge          | VERB     | VB       | conj        | xxxx     |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "change          | change          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "fee             | fee             | NOUN     | NN       | dobj        | xxx      |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "While           | while           | ADP      | IN       | mark        | Xxxxx    |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "Customer        | customer        | NOUN     | NN       | nsubj       | Xxxxx    |        1 |        0 |\n",
      "may             | may             | VERB     | MD       | aux         | xxx      |        1 |        0 |\n",
      "pay             | pay             | VERB     | VB       | advcl       | xxx      |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "difference      | difference      | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "airfare         | airfare         | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Customer        | customer        | NOUN     | NN       | nsubjpass   | Xxxxx    |        1 |        0 |\n",
      "will            | will            | VERB     | MD       | aux         | xxxx     |        1 |        0 |\n",
      "not             | not             | ADV      | RB       | neg         | xxx      |        1 |        0 |\n",
      "be              | be              | VERB     | VB       | auxpass     | xx       |        1 |        0 |\n",
      "charged         | charge          | VERB     | VBN      | ROOT        | xxxx     |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "change          | change          | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "fee             | fee             | NOUN     | NN       | dobj        | xxx      |        1 |        0 |\n",
      "on              | on              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "top             | top             | NOUN     | NN       | pobj        | xxx      |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "any             | any             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "difference      | difference      | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "airfare         | airfare         | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "Also            | also            | ADV      | RB       | advmod      | Xxxx     |        1 |        0 |\n",
      "unlike          | unlike          | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "most            | most            | ADJ      | JJS      | pobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "competitors     | competitor      | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "does            | do              | VERB     | VBZ      | aux         | xxxx     |        1 |        0 |\n",
      "not             | not             | ADV      | RB       | neg         | xxx      |        1 |        0 |\n",
      "impose          | impose          | VERB     | VB       | ROOT        | xxxx     |        1 |        0 |\n",
      "additional      | additional      | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "fees            | fee             | NOUN     | NNS      | dobj        | xxxx     |        1 |        0 |\n",
      "for             | for             | ADP      | IN       | prep        | xxx      |        1 |        0 |\n",
      "items           | item            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "such            | such            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "as              | as              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "seat            | seat            | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "selection       | selection       | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "snacks          | snack           | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "curb            | curb            | VERB     | VB       | compound    | xxxx     |        1 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "side            | side            | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "check           | check           | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "in              | in              | NOUN     | NN       | prep        | xx       |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "telephone       | telephone       | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "reservations    | reservation     | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "In              | in              | ADP      | IN       | prep        | Xx       |        1 |        0 |\n",
      "addition        | addition        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "allows          | allow           | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 |\n",
      "each            | each            | DET      | DT       | det         | xxxx     |        1 |        0 |\n",
      "ticketed        | ticket          | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "Customer        | customer        | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "check           | check           | VERB     | VB       | ccomp       | xxxx     |        1 |        0 |\n",
      "one             | one             | NUM      | CD       | nummod      | xxx      |        1 |        0 |\n",
      "stroller        | stroller        | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "one             | one             | NUM      | CD       | nummod      | xxx      |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car             | car             | NOUN     | NN       | compound    | xxx      |        1 |        0 |\n",
      "seat            | seat            | NOUN     | NN       | npadvmod    | xxxx     |        1 |        0 |\n",
      "free            | free            | ADJ      | JJ       | conj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "charge          | charge          | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "addition        | addition        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "to              | to              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "two             | two             | NUM      | CD       | nummod      | xxx      |        1 |        0 |\n",
      "free            | free            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "checked         | check           | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "bags            | bag             | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "also            | also            | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "continues       | continue        | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "promote         | promote         | VERB     | VB       | xcomp       | xxxx     |        1 |        0 |\n",
      "all             | all             | DET      | DT       | dobj        | xxx      |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "many            | many            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "other           | other           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "reasons         | reason          | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "fly             | fly             | VERB     | VB       | relcl       | xxx      |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | dobj        | Xxxxx    |        1 |        0 |\n",
      "such            | such            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "as              | as              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "low             | low             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "fares           | fare            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "network         | network         | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "size            | size            | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "Customer        | customer        | PROPN    | NNP      | compound    | Xxxxx    |        1 |        0 |\n",
      "Service         | service         | PROPN    | NNP      | conj        | Xxxxx    |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "free            | free            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "live            | live            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "television      | television      | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "offerings       | offering        | NOUN     | NNS      | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "Rapid           | rapid           | PROPN    | NNP      | nmod        | Xxxxx    |        1 |        0 |\n",
      "Rewards         | rewards         | PROPN    | NNP      | nmod        | Xxxxx    |        1 |        0 |\n",
      "frequent        | frequent        | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "flyer           | flyer           | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "program         | program         | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "In              | in              | ADP      | IN       | prep        | Xx       |        1 |        0 |\n",
      "2014            | 2014            | NUM      | CD       | pobj        | dddd     |        0 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "launched        | launch          | VERB     | VBD      | ROOT        | xxxx     |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "new             | new             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "visual          | visual          | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "expression      | expression      | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "brand           | brand           | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "Heart           | heart           | NOUN     | NN       | preconj     | Xxxxx    |        1 |        0 |\n",
      "-               | -               | PUNCT    | :        | punct       | -        |        0 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "symbolize       | symbolize       | VERB     | VB       | pcomp       | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "care            | care            | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trust           | trust           | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "belief          | belief          | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "providing       | provide         | VERB     | VBG      | pcomp       | xxxx     |        1 |        0 |\n",
      "exceptional     | exceptional     | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "Hospitality     | hospitality     | PROPN    | NNP      | dobj        | Xxxxx    |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "Employees’      | employees’      | PROPN    | NNPS     | compound    | Xxxxx’   |        0 |        0 |\n",
      "dedication      | dedication      | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "                |                 | SPACE    |          |             |          |        0 |        0 |\n",
      "to              | to              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "connecting      | connect         | VERB     | VBG      | pcomp       | xxxx     |        1 |        0 |\n",
      "Customers       | customer        | NOUN     | NNS      | dobj        | Xxxxx    |        1 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "what            | what            | NOUN     | WP       | nsubj       | xxxx     |        1 |        0 |\n",
      "is              | be              | VERB     | VBZ      | pcomp       | xx       |        1 |        0 |\n",
      "important       | important       | ADJ      | JJ       | acomp       | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "their           | -PRON-          | ADJ      | PRP$     | poss        | xxxx     |        1 |        0 |\n",
      "lives           | life            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "introduced      | introduce       | VERB     | VBD      | ROOT        | xxxx     |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "new             | new             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "Heart           | heart           | NOUN     | NN       | compound    | Xxxxx    |        1 |        0 |\n",
      "aircraft        | aircraft        | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "livery          | livery          | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "airport         | airport         | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "experience      | experience      | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "logo            | logo            | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "Aircraft        | aircraft        | NOUN     | NN       | nsubjpass   | Xxxxx    |        1 |        0 |\n",
      "already         | already         | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "fleet           | fleet           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "were            | be              | VERB     | VBD      | auxpass     | xxxx     |        1 |        0 |\n",
      "scheduled       | schedule        | VERB     | VBN      | ROOT        | xxxx     |        1 |        0 |\n",
      "to              | to              | PART     | TO       | aux         | xx       |        1 |        0 |\n",
      "receive         | receive         | VERB     | VB       | xcomp       | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "newly           | newly           | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "painted         | paint           | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "livery          | livery          | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "within          | within          | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "aircraft        | aircraft        | NOUN     | NN       | poss        | xxxx     |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "existing        | exist           | VERB     | VBG      | amod        | xxxx     |        1 |        0 |\n",
      "repainting      | repaint         | VERB     | VBG      | compound    | xxxx     |        1 |        0 |\n",
      "schedule        | schedule        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "while           | while           | ADP      | IN       | mark        | xxxx     |        1 |        0 |\n",
      "new             | new             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "aircraft        | aircraft        | NOUN     | NN       | nsubjpass   | xxxx     |        1 |        0 |\n",
      "have            | have            | VERB     | VBP      | aux         | xxxx     |        1 |        0 |\n",
      "been            | be              | VERB     | VBN      | auxpass     | xxxx     |        1 |        0 |\n",
      "delivered       | deliver         | VERB     | VBN      | advcl       | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Heart           | heart           | NOUN     | NN       | compound    | Xxxxx    |        1 |        0 |\n",
      "livery          | livery          | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "In              | in              | ADP      | IN       | prep        | Xx       |        1 |        0 |\n",
      "2016            | 2016            | NUM      | CD       | pobj        | dddd     |        0 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company         | company         | PROPN    | NNP      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "unveiled        | unveil          | VERB     | VBD      | ROOT        | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "next            | next            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "phase           | phase           | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Heart           | heart           | PROPN    | NNP      | compound    | Xxxxx    |        1 |        0 |\n",
      "brand           | brand           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "introduction    | introduction    | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "its             | -PRON-          | ADJ      | PRP$     | poss        | xxx      |        1 |        0 |\n",
      "first           | first           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "aircraft        | aircraft        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "new             | new             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "Heart           | heart           | NOUN     | NN       | compound    | Xxxxx    |        1 |        0 |\n",
      "cabin           | cabin           | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "interior        | interior        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "The             | the             | DET      | DT       | det         | Xxx      |        1 |        0 |\n",
      "new             | new             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "737             | 737             | NUM      | CD       | nummod      | ddd      |        0 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "800             | 800             | NUM      | CD       | nummod      | ddd      |        0 |        0 |\n",
      "interiors       | interior        | NOUN     | NNS      | nsubj       | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "which           | which           | ADJ      | WDT      | nsubjpass   | xxxx     |        1 |        0 |\n",
      "will            | will            | VERB     | MD       | aux         | xxxx     |        1 |        0 |\n",
      "also            | also            | ADV      | RB       | advmod      | xxxx     |        1 |        0 |\n",
      "be              | be              | VERB     | VB       | auxpass     | xx       |        1 |        0 |\n",
      "included        | include         | VERB     | VBN      | relcl       | xxxx     |        1 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "737             | 737             | NUM      | CD       | nummod      | ddd      |        0 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "8               | 8               | NUM      | CD       | prep        | d        |        0 |        0 |\n",
      "aircraft        | aircraft        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "give            | give            | VERB     | VB       | ROOT        | xxxx     |        1 |        0 |\n",
      "Southwest       | southwest       | PROPN    | NNP      | compound    | Xxxxx    |        1 |        0 |\n",
      "Customers       | customer        | NOUN     | NNS      | dative      | Xxxxx    |        1 |        0 |\n",
      "a               | a               | DET      | DT       | det         | x        |        1 |        0 |\n",
      "look            | look            | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "feel            | feel            | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "future          | future          | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "with            | with            | ADP      | IN       | prep        | xxxx     |        1 |        0 |\n",
      "bold            | bold            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "blue            | blue            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "seats           | seat            | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "additional      | additional      | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "seat            | seat            | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "width           | width           | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "legroom         | legroom         | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "an              | an              | DET      | DT       | det         | xx       |        1 |        0 |\n",
      "adjustable      | adjustable      | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "headrest        | headrest        | NOUN     | NN       | appos       | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "enhanced        | enhance         | VERB     | VBN      | conj        | xxxx     |        1 |        0 |\n",
      "back            | back            | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "comfort         | comfort         | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "extra           | extra           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "room            | room            | NOUN     | NN       | conj        | xxxx     |        1 |        0 |\n",
      "for             | for             | ADP      | IN       | prep        | xxx      |        1 |        0 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal        | personal        | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "belongings      | belonging       | NOUN     | NNS      | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "In              | in              | ADP      | IN       | prep        | Xx       |        1 |        0 |\n",
      "addition        | addition        | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "in              | in              | ADP      | IN       | prep        | xx       |        1 |        0 |\n",
      "mid-2017        | mid-2017        | NOUN     | NN       | pobj        | xxx-dddd |        0 |        0 |\n",
      ",               | ,               | PUNCT    | ,        | punct       | ,        |        0 |        0 |\n",
      "front           | front           | ADJ      | JJ       | amod        | xxxx     |        1 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "line            | line            | NOUN     | NN       | compound    | xxxx     |        1 |        0 |\n",
      "Employees       | employee        | NOUN     | NNS      | nsubj       | Xxxxx    |        1 |        0 |\n",
      "will            | will            | VERB     | MD       | aux         | xxxx     |        1 |        0 |\n",
      "begin           | begin           | VERB     | VB       | ROOT        | xxxx     |        1 |        0 |\n",
      "wearing         | wear            | VERB     | VBG      | xcomp       | xxxx     |        1 |        0 |\n",
      "Employee        | employee        | NOUN     | NN       | npadvmod    | Xxxxx    |        1 |        0 |\n",
      "-               | -               | PUNCT    | HYPH     | punct       | -        |        0 |        0 |\n",
      "designed        | design          | VERB     | VBN      | amod        | xxxx     |        1 |        0 |\n",
      "uniforms        | uniform         | NOUN     | NNS      | dobj        | xxxx     |        1 |        0 |\n",
      "that            | that            | ADJ      | WDT      | nsubj       | xxxx     |        1 |        0 |\n",
      "highlight       | highlight       | VERB     | VBP      | relcl       | xxxx     |        1 |        0 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        0 |\n",
      "Company         | company         | PROPN    | NNP      | poss        | Xxxxx    |        1 |        0 |\n",
      "’s              | ’s              | PART     | POS      | case        | ’x       |        0 |        0 |\n",
      "red             | red             | ADJ      | JJ       | amod        | xxx      |        1 |        0 |\n",
      "and             | and             | CCONJ    | CC       | cc          | xxx      |        1 |        0 |\n",
      "blue            | blue            | ADJ      | JJ       | conj        | xxxx     |        1 |        0 |\n",
      "Heart           | heart           | PROPN    | NNP      | compound    | Xxxxx    |        1 |        0 |\n",
      "brand           | brand           | NOUN     | NN       | dobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n"
     ]
    }
   ],
   "source": [
    "print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | '.format(\n",
    "    'text', 'lemma_', 'pos_', 'tag_', 'dep_', 'shape_', 'is_alpha', 'is_stop'))\n",
    "print('_'*104)\n",
    "\n",
    "for token in doc:\n",
    "    print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} |'.format(\n",
    "          token.text, token.lemma_, token.pos_, token.tag_, token.dep_\n",
    "        , token.shape_, token.is_alpha, token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\alsherman\\AppData\\Local\\Continuum\\anaconda3\\envs\\guild\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Serving on port 5000...\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "\n",
    "A named entity is a \"real-world object\" that's assigned a name – for example, a person, a country, a product or a book title. spaCy can recognise various types of named entities in a document, by asking the model for a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print('label: {:10} | entitiy: {:50} '.format(ent.label_, ent.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the named entities tagged as PERSON\n",
    "for ent in doc.ents:\n",
    "    if 'PERSON' in ent.label_:\n",
    "        print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the named entities tagged as ORG (organization)\n",
    "for ent in doc.ents:\n",
    "    if 'ORG' in ent.label_:\n",
    "        print(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:15} | {:5} | {:10} | {:40}'.format('Text','Root','Dependency','Root Text'))\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('{:15} | {:5} | {:10} | {:40}'.format(\n",
    "        chunk.root.text, chunk.root.dep_,chunk.root.head.text, chunk.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Identify Relevant Text (Rule-based Matching)\n",
    "\n",
    "Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions. We will use this to filter and extract relevant text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_basesd_matching_url = 'https://spacy.io/usage/linguistic-features#rule-based-matching'\n",
    "iframe = '<iframe src={} width=1000 height=700></iframe>'.format(rule_basesd_matching_url)\n",
    "HTML(iframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Matcher identifies text based off rules we specify\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to specify what to do with the text we collect\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    \"\"\"  collect and transform text\n",
    "\n",
    "    :param i: is the index of the text matches\n",
    "    :param matches: is the text that we match\n",
    "    :param doc: is the full\n",
    "    \"\"\"\n",
    "    \n",
    "    match_id, start, end = matches[i]  # indices of matched term\n",
    "    span = doc[start : end] # extract matched term\n",
    "    \n",
    "    print('span: {} | start:{:5} | end:{:5} | id:{}'.format(\n",
    "        span, start, end, match_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a pattern of text to collect\n",
    "# we can add complex rules to match\n",
    "pattern = [{'LOWER':'fee'}]\n",
    "\n",
    "# instantiate matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# add pattern\n",
    "matcher.add('fee', collect_sents, pattern)\n",
    "\n",
    "# pass the doc to the matcher to run the collect_sents function\n",
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the function to print the sentence of the matched term (span)\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end]\n",
    "    print('SPAN {}'.format(span))\n",
    "    print('SENT: {}'.format(span.sent))\n",
    "    print()\n",
    "\n",
    "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'fee'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('fee', collect_sents, pattern)\n",
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the function to collect sentences\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end]\n",
    "    # update matched data collections\n",
    "    matched_sents.append(span.sent)\n",
    "    \n",
    "matched_sents = []\n",
    "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'fee'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('fee', collect_sents, pattern)\n",
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review matches\n",
    "matched_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DefaultDict\n",
    "\n",
    "Usually, a Python dictionary throws a KeyError if you try to get an item with a key that is not currently in the dictionary. The defaultdict in contrast will simply create any items that you try to access (provided of course they do not exist yet). To create such a \"default\" item, it calls the function object that you pass in the constructor (more precisely, it's an arbitrary \"callable\" object, which includes function and type objects). For the first example, default items are created using int(), which will return the integer object 0. For the second example, default items are created using list(), which returns a new empty list object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "s = 'mississippi'\n",
    "\n",
    "d = defaultdict(int)\n",
    "for k in s:\n",
    "    d[k] += 1\n",
    "\n",
    "sorted(d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the function to count matches using defaultdict\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end]\n",
    "    # update matched data collections\n",
    "    ent_count[span.text] += 1  # key must be span.text not span!\n",
    "\n",
    "ent_count = defaultdict(int)\n",
    "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'fee'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('fee', collect_sents, pattern)\n",
    "matcher(doc)\n",
    "\n",
    "ent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect entity counts across all documents\n",
    "\n",
    "ent_count = defaultdict(int)\n",
    "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'fee'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('fee', collect_sents, pattern)\n",
    "\n",
    "for section in df['section_text'][0:10]:\n",
    "    matcher(nlp(section)) # match on your text\n",
    "\n",
    "ent_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "get all sentences with word risk for topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'POS': 'NOUN', 'OP': '+'},{'LOWER':'fee'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('risk', collect_sents, pattern)\n",
    "\n",
    "years = {}\n",
    "for ind, row in df.iterrows():\n",
    "    if ind == 10:\n",
    "        break\n",
    "    ent_count = defaultdict(int)\n",
    "    year = row['filename']\n",
    "    text = row['section_text']\n",
    "    doc = nlp(text)\n",
    "    matcher(doc) # match on your text\n",
    "    years[year] = ent_count\n",
    "\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(years).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Matching\n",
    "\n",
    "When using rule-based matching, SpaCy may match the same term multiple times if it is part of different n-term pairs with one term contained in another. For instance, 'integration services' in 'system integration services.'\n",
    "\n",
    "To avoid matching these terms multiple times, we can add to the collect_sents function to check if each term is contained in the previous term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]\n",
    "    sent = span.sent\n",
    "\n",
    "    # lemmatize the matched spans\n",
    "    entity = span.lemma_.lower()\n",
    "            \n",
    "    # explicity add the first entity without checking if it matches other terms\n",
    "    # as there is no previous span to check    \n",
    "    if i == 0:\n",
    "        ent_count[entity] += 1\n",
    "        ent_sents[entity].append(sent)\n",
    "        matched_sents.append(sent)\n",
    "        return\n",
    "\n",
    "    # get the span, entity, and sentence from the previous match\n",
    "    # if more than one match exist\n",
    "    last_match_id, last_start, last_end = matches[i-1]\n",
    "    last_span = doc[last_start : last_end]\n",
    "    last_entity = last_span.text.lower()\n",
    "    last_sent = last_span.sent\n",
    "\n",
    "    # to avoid adding duplicates when one term is contained in another \n",
    "    # (e.g. 'integration services' in 'system integration services')\n",
    "    # make sure new spans are unique\n",
    "    distinct_entity = (entity not in last_entity) or (sent != last_sent)\n",
    "    not_duplicate_entity = (entity != last_entity) or (sent != last_sent)\n",
    "    \n",
    "    # update collections for unique data\n",
    "    if distinct_entity and not_duplicate_entity:\n",
    "        ent_count[entity] += 1\n",
    "        ent_sents[entity].append(sent)\n",
    "        matched_sents.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Patterns\n",
    "\n",
    "SpaCy matchers can use multiple patterns. Each pattern can be added to the Matcher individually with match.add and can use their own collect_sents function. Or use *patterns to add multiple patterns to the matcher at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sents = []\n",
    "ent_sents  = defaultdict(list)\n",
    "ent_count = defaultdict(int)\n",
    "\n",
    "# multiple patterns\n",
    "pattern = [[{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'fee'}]\n",
    "           , [{'POS': 'NOUN', 'OP': '+'},{'LOWER': 'fees'}]]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# *patterns to add multiple patterns with the same collect_sents function\n",
    "matcher.add('ProductTypes', collect_sents, *pattern)\n",
    "matches = matcher(doc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc): \n",
    "    # Add named entities, but only if they are a compound of more than word.\n",
    "    IGNORE_ENTS = ('QUANTITY','ORDINAL','CARDINAL','DATE'\n",
    "                   ,'PERCENT','MONEY','TIME')\n",
    "    ents = doc.ents\n",
    "    ents = [ent for ent in ents if \n",
    "             (ent.label_ not in IGNORE_ENTS) and (len(ent) > 2)]\n",
    "    \n",
    "    # add underscores to combine words in entities\n",
    "    ents = [str(ent).strip().replace(' ','_') for ent in ents]\n",
    " \n",
    "    # Keep only words (no numbers, no punctuation).\n",
    "    # Lemmatize tokens, remove punctuation and remove stopwords.\n",
    "    doc = [token.lemma_ for token in doc \n",
    "           if token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    doc.extend([entity for entity in ents])\n",
    "    \n",
    "    return [str(term) for term in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cleaned_text = []\n",
    "for sent in matched_sents:\n",
    "    text = clean_text(sent)\n",
    "    cleaned_text.append(text)\n",
    "\n",
    "print(cleaned_text[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:guild]",
   "language": "python",
   "name": "conda-env-guild-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
